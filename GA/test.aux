\relax 
\catcode `"\active 
\select@language{swedish}
\@writefile{toc}{\select@language{swedish}}
\@writefile{lof}{\select@language{swedish}}
\@writefile{lot}{\select@language{swedish}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Inledning}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Bakgrund}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Syfte}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Fr\IeC {\r a}gest\IeC {\"a}llning}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Metod}{5}}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bakgrund}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tensorer, indexering och notation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feed-forward neurala n\IeC {\"a}tverk}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Fram\IeC {\r a}tprogagering}{6}}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\newlabel{figFCC}{{3.2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Ett exempel p\IeC {\r a} ett enkelt feed-forward neuralt n\IeC {\"a}tverk. Inputneuronerna \IeC {\"a}r bl\IeC {\r a}markerade medan resterande neuroner \IeC {\"a}r orangea. R\IeC {\"o}da neuroner \IeC {\"a}r s\IeC {\r a} kallade \textit  {bias-neuroner} som \IeC {\"a}r konstanta oberoende p\IeC {\r a} inmatningsdatan. Svarta linjer symboliserar vikterna och styrkan mellan tv\IeC {\r a} neuroner.}}{7}}
\newlabel{feed-forward}{{3}{7}}
\citation{cs231n}
\citation{wikiStanford}
\newlabel{aktiveringsfunktion}{{3.2.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Grafen av aktiveringsfunktionerna $ReLU$, $\sigma $ och $tanh$.}}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Kostnadsfunktionen}{8}}
\citation{gradient}
\citation{convmath}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\citation{figSGD}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\citation{wikiStanford}
\citation{gradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Gradient Descent}{9}}
\newlabel{SGD}{{12}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Bak\IeC {\r a}tpropagering}{9}}
\citation{cs231n}
\citation{cs231n}
\newlabel{figSGD}{{3.2.3}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces En illustration av gradient descent p\IeC {\r a} en funktion med tv\IeC {\r a} variabler.\cite  {figSGD}}}{10}}
\newlabel{dLdW_FCC}{{15}{10}}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\newlabel{dLdb_FCC}{{16}{11}}
\newlabel{dLdX_FCC}{{18}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Tr\IeC {\"a}ning av neurala n\IeC {\"a}tverk}{11}}
\citation{cs231n}
\citation{cs231n}
\@writefile{toc}{\contentsline {section}{\numberline {4}Resultat}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Konvolutionella neuala n\IeC {\"a}tverk}{13}}
\newlabel{figkatter}{{4.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Resultatet av att ett filter f\IeC {\"o}r vertikal respektive horizontell kantdetektering har sammanrullat \IeC {\"o}ver en bild av en katt.}}{13}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{figboatcnn}
\citation{figboatcnn}
\citation{cs231n}
\citation{convmath}
\newlabel{CNNeq}{{19}{14}}
\newlabel{figboatcnn}{{4.1}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces En illustration av ett konvolutionellt neuralt n\IeC {\"a}tverk. Varje skiva \IeC {\"a}r en egen \textit  {feature map}. \cite  {figboatcnn}}}{14}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{figkonv}
\citation{figkonv}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Konvolutionslagret fram\IeC {\r a}tpropagering}{15}}
\newlabel{figkonv}{{4.1.1}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces En k\IeC {\"a}rna med storlek $3 \times 3$ sammanrullar \IeC {\"o}ver ett omr\IeC {\r a}de med dimensioner $6 \times 6$ och bildar en aktivering med dimensionerna $4 \times 4$. \cite  {figkonv}}}{15}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{convmath}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\newlabel{figzeropad}{{4.1.1}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Ett omr\IeC {\r a}de med dimensioner $3 \times 3$ zero-paddas med $p=1$ och resulterande omr\IeC {\r a}de f\IeC {\r a}r dimensioner $5 \times 5$.}}{16}}
\newlabel{konvolution}{{24}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Konvolutionslagret bak\IeC {\r a}tpropagering}{16}}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{cs231n}
\newlabel{konvolutionbackprop}{{25}{17}}
\citation{cs231n}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{convmath}
\citation{cs231n}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Aktiveringsfunktionslager fram\IeC {\r a}tpropagering}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Aktiveringsfunktionslager bak\IeC {\r a}tpropagering}{18}}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}Maxpoollagret fram\IeC {\r a}tpropagation}{19}}
\newlabel{figmaxpool}{{4.1.5}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Maxpooling med $k=2$ och $s=2$ av ett omr\IeC {\r a}de med dimensioner $4 \times 4$ d\IeC {\"a}r resultatet bildar ett omr\IeC {\r a}de med dimensionerna $2 \times 2$.}}{19}}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{batchnorm}
\newlabel{maxpool}{{34}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.6}Maxpoollagret bak\IeC {\r a}tpropagering}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.7}Batch Normalization fram\IeC {\r a}tpropagering}{20}}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.8}Batch Normalization bak\IeC {\r a}tpropagering}{22}}
\newlabel{kroneckerdelta}{{43}{22}}
\newlabel{kroneckerdeltaDERIVATIVE}{{44}{22}}
\newlabel{kroneckerdeltaSUM}{{45}{22}}
\newlabel{BN_delta_error}{{46}{22}}
\newlabel{BN_dxdxhat}{{47}{22}}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\newlabel{BN_kedjeregeln}{{48}{23}}
\newlabel{mu'}{{49}{23}}
\newlabel{sigma'}{{50}{23}}
\citation{webBN1}
\citation{webBN2}
\newlabel{finalBNeq}{{51}{24}}
\citation{cs231n}
\citation{cs231n}
\citation{notesonbackprop}
\citation{websoftmax}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.9}Softmax fram\IeC {\r a}tpropagering}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.10}Softmax bak\IeC {\r a}tpropagering}{25}}
\citation{MNIST}
\citation{cs231n}
\citation{MNIST}
\citation{cs231n}
\citation{notesonbackprop}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Praktiska Till\IeC {\"a}mpningar}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Klassificering av handskrivna siffror}{26}}
\newlabel{figMNIST}{{4.2.1}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Tio bilder av handskrivna siffror fr\IeC {\r a}n MNIST DATASETET. \cite  {MNIST}}}{27}}
\newlabel{figkosnadmnist}{{4.2.1}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces En graf av kostnaden som funktion av antalet iterationer med mini-hopstorleken 100 bilder med modell 2.}}{29}}
\newlabel{figepokmnist}{{4.2.1}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces En graf av validationsprecisionen som funktion av antalet epoker av 60 000 bilder med modell 2.}}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Objektdetektering i bilder}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Ansiktsigenk\IeC {\"a}nning}{29}}
\bibcite{cs231n}{1}
\bibcite{notesonbackprop}{2}
\bibcite{convmath}{3}
\bibcite{convarithmetic}{4}
\bibcite{highperformanceconv}{5}
\bibcite{wikiStanford}{6}
\bibcite{gradient}{7}
\bibcite{yolo}{8}
\bibcite{resnet}{9}
\bibcite{batchnorm}{10}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{30}}
\bibcite{webconv1}{11}
\bibcite{webBN1}{12}
\bibcite{webconv2}{13}
\bibcite{webBN2}{14}
\bibcite{webconv3}{15}
\bibcite{websoftmax}{16}
\bibcite{MNIST}{17}
\bibcite{figSGD}{18}
\bibcite{figboatcnn}{19}
\bibcite{figkonv}{20}
\bibcite{figconv}{21}
