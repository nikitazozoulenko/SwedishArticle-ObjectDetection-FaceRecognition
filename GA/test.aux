\relax 
\catcode `"\active 
\select@language{swedish}
\@writefile{toc}{\select@language{swedish}}
\@writefile{lof}{\select@language{swedish}}
\@writefile{lot}{\select@language{swedish}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduktion}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Syfte}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Fr\IeC {\r a}gest\IeC {\"a}llning}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Metod}{5}}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{wikiStanford}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bakgrund}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tensorer, indexering och notation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feed-forward Neurala N\IeC {\"a}tverk}{6}}
\newlabel{figFCC}{{3.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Ett exempel p\IeC {\r a} ett enkelt feed-forward neuralt n\IeC {\"a}tverk. Inputneuronerna \IeC {\"a}r bl\IeC {\r a}markerade medan resterande neuroner \IeC {\"a}r orangea. R\IeC {\"o}da neuroner \IeC {\"a}r s\IeC {\r a} kallade \textit  {bias-neuroner} som \IeC {\"a}r konstanta oberoende p\IeC {\r a} inmatningsdatan. Svarta linjer symboliserar vikterna och styrkan mellan tv\IeC {\r a} neuroner.}}{6}}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Fram\IeC {\r a}tprogagering}{7}}
\newlabel{feed-forward}{{3}{7}}
\citation{cs231n}
\citation{wikiStanford}
\newlabel{aktiveringsfunktion}{{3.2.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Grafen av aktiveringsfunktionerna $ReLU$, $\sigma $ och $tanh$.}}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Kostnadsfunktionen}{8}}
\citation{gradient}
\citation{convmath}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\citation{figSGD}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Gradient Descent}{9}}
\newlabel{SGD}{{12}{9}}
\newlabel{figSGD}{{3.2.3}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces En illustration av gradient descent p\IeC {\r a} en funktion med tv\IeC {\r a} variabler.\cite  {figSGD}}}{9}}
\citation{wikiStanford}
\citation{gradient}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Bak\IeC {\r a}tpropagering}{10}}
\newlabel{dLdW_FCC}{{15}{10}}
\newlabel{dLdb_FCC}{{16}{10}}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\newlabel{dLdX_FCC}{{18}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Tr\IeC {\"a}ning av neurala n\IeC {\"a}tverk}{11}}
\citation{cs231n}
\citation{cs231n}
\@writefile{toc}{\contentsline {section}{\numberline {4}Resultat}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Konvolutionella Neuala Netv\IeC {\"a}rk}{12}}
\newlabel{figkatter}{{4.1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Resultatet av att ett filter f\IeC {\"o}r vertikal respektive horizontell kantdetektering har sammanrullat \IeC {\"o}ver en bild av en katt.}}{12}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{figboatcnn}
\citation{figboatcnn}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\newlabel{CNNeq}{{19}{13}}
\newlabel{figboatcnn}{{4.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces En illustration av ett konvolutionellt neuralt n\IeC {\"a}tverk. Varje skiva \IeC {\"a}r en egen feature map. \cite  {figboatcnn}}}{13}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{figkonv}
\citation{figkonv}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Konvolutionslagret fram\IeC {\r a}tpropagering}{14}}
\newlabel{figkonv}{{4.1.1}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces En k\IeC {\"a}rna med storlek $3 \times 3$ sammanrullar \IeC {\"o}ver ett omr\IeC {\r a}de med dimensioner $6 \times 6$ och bildar en aktivering med dimensionerna $4 \times 4$. \cite  {figkonv}}}{14}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{convmath}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\newlabel{figzeropad}{{4.1.1}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Ett omr\IeC {\r a}de med dimensioner $3 \times 3$ zero-paddas med $p=1$ och resulterande omr\IeC {\r a}de f\IeC {\r a}r dimensioner $5 \times 5$.}}{15}}
\newlabel{konvolution}{{24}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Konvolutionslagret bak\IeC {\r a}tpropagering}{15}}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{cs231n}
\newlabel{konvolutionbackprop}{{25}{16}}
\citation{cs231n}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{convmath}
\citation{cs231n}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Aktiveringsfunktionslager fram\IeC {\r a}tpropagering}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Aktiveringsfunktionslager bak\IeC {\r a}tpropagering}{17}}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}Maxpoollagret fram\IeC {\r a}tpropagation}{18}}
\newlabel{figmaxpool}{{4.1.5}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Maxpooling med $k=2$ och $s=2$ av ett omr\IeC {\r a}de med dimensioner $4 \times 4$ d\IeC {\"a}r resultatet bildar ett omr\IeC {\r a}de med dimensionerna $2 \times 2$.}}{18}}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{batchnorm}
\newlabel{maxpool}{{34}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.6}Maxpoollagret bak\IeC {\r a}tpropagering}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.7}Batch Normalization fram\IeC {\r a}tpropagering}{19}}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.8}Batch Normalization bak\IeC {\r a}tpropagering}{21}}
\newlabel{kroneckerdelta}{{43}{21}}
\newlabel{kroneckerdeltaDERIVATIVE}{{44}{21}}
\newlabel{kroneckerdeltaSUM}{{45}{21}}
\newlabel{BN_delta_error}{{46}{21}}
\newlabel{BN_dxdxhat}{{47}{21}}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\newlabel{BN_kedjeregeln}{{48}{22}}
\newlabel{mu'}{{49}{22}}
\newlabel{sigma'}{{50}{22}}
\citation{webBN1}
\citation{webBN2}
\newlabel{finalBNeq}{{51}{23}}
\citation{cs231n}
\citation{cs231n}
\citation{notesonbackprop}
\citation{websoftmax}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.9}Softmax fram\IeC {\r a}tpropagering}{24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.10}Softmax bak\IeC {\r a}tpropagering}{24}}
\citation{MNIST}
\citation{cs231n}
\citation{MNIST}
\citation{cs231n}
\citation{notesonbackprop}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Praktiska Till\IeC {\"a}mpningar}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Klassificering av handskrivna siffror}{25}}
\newlabel{figMNIST}{{4.2.1}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Tio bilder av handskrivna siffror fr\IeC {\r a}n MNIST DATASETET. \cite  {MNIST}}}{26}}
\newlabel{figkosnadmnist}{{4.2.1}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces En graf av kostnaden som funktion av antalet iterationer med mini-hopstorleken 100 bilder med modell 2.}}{28}}
\newlabel{figepokmnist}{{4.2.1}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces En graf av validationsprecisionen som funktion av antalet epoker av 60 000 bilder med modell 2.}}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Objektdetektering i bilder}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Ansiktsigenk\IeC {\"a}nning}{28}}
\bibcite{cs231n}{1}
\bibcite{notesonbackprop}{2}
\bibcite{convmath}{3}
\bibcite{convarithmetic}{4}
\bibcite{highperformanceconv}{5}
\bibcite{wikiStanford}{6}
\bibcite{gradient}{7}
\bibcite{yolo}{8}
\bibcite{resnet}{9}
\bibcite{batchnorm}{10}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{29}}
\@writefile{toc}{\contentsline {section}{Referenser}{29}}
\bibcite{webconv1}{11}
\bibcite{webBN1}{12}
\bibcite{webconv2}{13}
\bibcite{webBN2}{14}
\bibcite{webconv3}{15}
\bibcite{websoftmax}{16}
\bibcite{MNIST}{17}
\bibcite{figSGD}{18}
\bibcite{figboatcnn}{19}
\bibcite{figkonv}{20}
\bibcite{figconv}{21}
