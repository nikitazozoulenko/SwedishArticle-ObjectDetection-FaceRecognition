\relax 
\catcode `"\active 
\select@language{swedish}
\@writefile{toc}{\select@language{swedish}}
\@writefile{lof}{\select@language{swedish}}
\@writefile{lot}{\select@language{swedish}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduktion}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Bakgrund}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Syfte}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Fr\IeC {\r a}gest\IeC {\"a}llning}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Metod}{5}}
\citation{convmath}
\citation{cs231n}
\@writefile{toc}{\contentsline {section}{\numberline {3}Tensorer, indexering och notation}{6}}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\citation{wikiStanford}
\@writefile{toc}{\contentsline {section}{\numberline {4}Resultat}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Feed-forward Neurala N\IeC {\"a}tverk}{7}}
\newlabel{figFCC}{{4.1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Ett exempel p\IeC {\r a} ett enkelt feed-forward neuralt n\IeC {\"a}tverk. Inputneuronerna \IeC {\"a}r bl\IeC {\r a}markerade medan resterande neuroner \IeC {\"a}r orangea. R\IeC {\"o}da neuroner \IeC {\"a}r s\IeC {\r a} kallade \IeC {\textquotedblright }bias-neuroner\IeC {\textquotedblright } som \IeC {\"a}r konstanta oberoende p\IeC {\r a} inputdatan. Svarta linjer symboliserar vikterna och deras styrka mellan tv\IeC {\r a} neuroner.}}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Fram\IeC {\r a}tprogagering}{7}}
\citation{cs231n}
\citation{wikiStanford}
\citation{cs231n}
\newlabel{feed-forward}{{4}{8}}
\citation{cs231n}
\citation{cs231n}
\citation{wikiStanford}
\newlabel{aktiveringsfunktion}{{4.1.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Grafen av aktiveringsfunktionerna $ReLU$, $\sigma $ och $tanh$.}}{9}}
\citation{gradient}
\citation{convmath}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\citation{figSGD}
\citation{gradient}
\citation{convmath}
\citation{wikiStanford}
\citation{wikiStanford}
\citation{gradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Kostnadsfunktionen och gradient descent}{10}}
\newlabel{SGD}{{18}{10}}
\citation{cs231n}
\citation{convmath}
\newlabel{figSGD}{{4.1.2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces En illustration av gradient descent p\IeC {\r a} en funktion med tv\IeC {\r a} variabler \cite  {figSGD}}}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Bak\IeC {\r a}tpropagering}{11}}
\citation{cs231n}
\citation{convmath}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{wikiStanford}
\citation{convmath}
\citation{cs231n}
\citation{wikiStanford}
\citation{convmath}
\citation{cs231n}
\citation{cs231n}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Konvolutionella Neuala Netv\IeC {\"a}rk}{14}}
\citation{figboatcnn}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\newlabel{figkatter}{{4.2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Resultatet av ett en k\IeC {\"a}rna f\IeC {\"o}r horizontell och vertikal kantdetektering har sammanrullat \IeC {\"o}ver en bild av en katt.}}{15}}
\newlabel{figboatcnn}{{4.2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces En illustration av ett konvolutionellt neuralt n\IeC {\"a}tverk. \cite  {figboatcnn}}}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Konvolutionslagret fram\IeC {\r a}tpropagering}{15}}
\citation{figkonv}
\citation{figkonv}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\newlabel{figkonv}{{4.2.1}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces En k\IeC {\"a}rna med storlek $3 \times 3$ sammanrullar \IeC {\"o}ver ett omr\IeC {\r a}de med dimensioner $6 \times 6$ och bildar en aktivering med dimensionerna $4 \times 4$. \cite  {figkonv}}}{16}}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{convmath}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\newlabel{figzeropad}{{4.2.1}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Ett omr\IeC {\r a}de med dimensioner $3 \times 3$ zero-paddas med $p=1$ och resulterande omr\IeC {\r a}de f\IeC {\r a}r dimensioner $5 \times 5$.}}{17}}
\newlabel{konvolution}{{39}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Konvolutionslagret bak\IeC {\r a}tpropagering}{17}}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\citation{webconv1}
\citation{webconv2}
\citation{webconv3}
\newlabel{konvolutionbackprop}{{40}{18}}
\citation{cs231n}
\citation{convmath}
\citation{cs231n}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Aktiveringsfunktionslager fram\IeC {\r a}tpropagering}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Aktiveringsfunktionslager bak\IeC {\r a}tpropagering}{19}}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\citation{convarithmetic}
\citation{cs231n}
\citation{convmath}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}Maxpoollagret fram\IeC {\r a}tpropagation}{20}}
\newlabel{figmaxpool}{{4.2.5}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Maxpooling med $k=2$ och $s=2$ av ett omr\IeC {\r a}de med dimensioner $4 \times 4$ d\IeC {\"a}r resultatet bildar ett omr\IeC {\r a}de med dimensionerna $2 \times 2$.}}{20}}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{convmath}
\citation{webconv3}
\citation{cs231n}
\citation{batchnorm}
\newlabel{maxpool}{{49}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6}Maxpoollagret bak\IeC {\r a}tpropagering}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7}Batch Normalization fram\IeC {\r a}tpropagering}{21}}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{cs231n}
\citation{batchnorm}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.8}Batch Normalization bak\IeC {\r a}tpropagering}{23}}
\newlabel{kroneckerdelta}{{58}{23}}
\newlabel{kroneckerdeltaDERIVATIVE}{{59}{23}}
\newlabel{kroneckerdeltaSUM}{{60}{23}}
\newlabel{BN_delta_error}{{61}{23}}
\newlabel{BN_dxdxhat}{{62}{23}}
\citation{webBN1}
\citation{webBN2}
\citation{webBN1}
\citation{webBN2}
\newlabel{BN_kedjeregeln}{{63}{24}}
\newlabel{mu'}{{64}{24}}
\newlabel{sigma'}{{65}{24}}
\citation{webBN1}
\citation{webBN2}
\citation{MNIST}
\citation{cs231n}
\citation{MNIST}
\citation{cs231n}
\citation{notesonbackprop}
\citation{websoftmax}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Praktiska Till\IeC {\"a}mpningar}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Klassificering av handskrivna siffror}{26}}
\citation{cs231n}
\citation{notesonbackprop}
\newlabel{figMNIST}{{4.3.1}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Tio bilder av handskrivna siffror fr\IeC {\r a}n MNIST DATASETET. \cite  {MNIST}}}{27}}
\bibcite{cs231n}{1}
\bibcite{notesonbackprop}{2}
\newlabel{figkosnadmnist}{{4.3.1}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces En graf av kostnadsfunktionen efter varje iteration av mini-hopen av 100 bilder.}}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Objektdetektering i bilder}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Ansiktsigenk\IeC {\"a}nning}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{29}}
\@writefile{toc}{\contentsline {section}{Referenser}{29}}
\bibcite{convmath}{3}
\bibcite{convarithmetic}{4}
\bibcite{highperformanceconv}{5}
\bibcite{wikiStanford}{6}
\bibcite{gradient}{7}
\bibcite{yolo}{8}
\bibcite{resnet}{9}
\bibcite{batchnorm}{10}
\newlabel{figepokmnist}{{4.3.1}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces En graf av validationsprecisionen efter varje epok av 60 000 bilder med modell 2.}}{30}}
\bibcite{webconv1}{11}
\bibcite{webBN1}{12}
\bibcite{webconv2}{13}
\bibcite{webBN2}{14}
\bibcite{webconv3}{15}
\bibcite{websoftmax}{16}
\bibcite{MNIST}{17}
\bibcite{figSGD}{18}
\bibcite{figboatcnn}{19}
\bibcite{figkonv}{20}
\bibcite{figconv}{21}
